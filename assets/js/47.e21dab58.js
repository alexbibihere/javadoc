(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{455:function(a,r,e){"use strict";e.r(r);var k=e(2),i=Object(k.a)({},(function(){var a=this,r=a._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h1",{attrs:{id:"kafka-简介"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kafka-简介"}},[a._v("#")]),a._v(" kafka 简介")]),a._v(" "),r("p",[a._v("kafka 是一种高吞吐量的分布式消息系统，它可以处理消费者生成的大量数据。它提供了一个分布式的提交日志，使得系统中的数据可以持久化，并可以从任何地方消费。kafka 被设计为一个分布式的、可扩展的、多分区的、多副本的消息系统。它最初由 LinkedIn 开发，并于 2011 年开源。\nkafka 主要有以下几个特点：")]),a._v(" "),r("ol",[r("li",[r("p",[a._v("高吞吐量：kafka 能处理消费者生成的大量数据，它可以提供实时的消费能力。")])]),a._v(" "),r("li",[r("p",[a._v("高容错性：kafka 集群中的各个节点都可以容忍部分节点失效，它可以保证消息的可靠性。")])]),a._v(" "),r("li",[r("p",[a._v("高可用性：kafka 集群中的各个节点都可以容忍部分节点失效，它可以保证消息的持久化。")])]),a._v(" "),r("li",[r("p",[a._v("灵活的消息分发：kafka 提供了多种消息分发的方式，包括轮询、随机、按 key 等。")])]),a._v(" "),r("li",[r("p",[a._v("实时数据分析：kafka 可以实时地消费数据并进行数据分析，这对于实时数据处理和实时数据分析是非常有用的。")])])]),a._v(" "),r("p",[a._v("kafka 的架构如下图所示：")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://kafka.apache.org/21/images/kafka_architecture.png",alt:"kafka-architecture"}})]),a._v(" "),r("p",[a._v("kafka 的主要组件包括：")]),a._v(" "),r("ol",[r("li",[r("p",[a._v("生产者：生产者负责产生消息并将其发送到 kafka 集群。")])]),a._v(" "),r("li",[r("p",[a._v("消费者：消费者负责从 kafka 集群中消费消息。")])]),a._v(" "),r("li",[r("p",[a._v("集群：kafka 集群由一个或多个服务器组成，它们之间通过 TCP 协议通信。")])]),a._v(" "),r("li",[r("p",[a._v("主题：主题是 kafka 中消息的分类，生产者和消费者可以向特定的主题发布和订阅消息。")])]),a._v(" "),r("li",[r("p",[a._v("分区：分区是 kafka 中消息的存储和分配单位，每个主题可以有多个分区。")])]),a._v(" "),r("li",[r("p",[a._v("副本：副本是 kafka 中消息的冗余备份，它可以提高消息的可靠性。")])]),a._v(" "),r("li",[r("p",[a._v("消息：消息是 kafka 中存储的基本单元，它包含一个键、一个值和一个时间戳。")])])]),a._v(" "),r("p",[a._v("kafka 的优点：")]),a._v(" "),r("ol",[r("li",[r("p",[a._v("高吞吐量：kafka 具有高吞吐量的特性，它可以处理消费者生成的大量数据。")])]),a._v(" "),r("li",[r("p",[a._v("高容错性：kafka 集群中的各个节点都可以容忍部分节点失效，它可以保证消息的可靠性。")])]),a._v(" "),r("li",[r("p",[a._v("高可用性：kafka 集群中的各个节点都可以容忍部分节点失效，它可以保证消息的持久化。")])]),a._v(" "),r("li",[r("p",[a._v("灵活的消息分发：kafka 提供了多种消息分发的方式，包括轮询、随机、按 key 等。")])]),a._v(" "),r("li",[r("p",[a._v("实时数据分析：kafka 可以实时地消费数据并进行数据分析，这对于实时数据处理和实时数据分析是非常有用的。")])])]),a._v(" "),r("p",[a._v("kafka 的缺点：")]),a._v(" "),r("ol",[r("li",[r("p",[a._v("复杂的架构：kafka 架构相对复杂，它需要一个 Zookeeper 集群来管理集群中的元数据。")])]),a._v(" "),r("li",[r("p",[a._v("依赖 Zookeeper：kafka 依赖 Zookeeper 集群来管理集群中的元数据，这会增加系统的复杂性。")])]),a._v(" "),r("li",[r("p",[a._v("性能损耗：kafka 集群的性能受限于磁盘 I/O 和网络带宽。")])])]),a._v(" "),r("p",[a._v("kafka 的适用场景：")]),a._v(" "),r("ol",[r("li",[r("p",[a._v("日志收集：kafka 适合于日志收集场景，它可以收集和处理大量的日志数据。")])]),a._v(" "),r("li",[r("p",[a._v("网站活动跟踪：kafka 适合于网站活动跟踪场景，它可以实时地消费网站的用户行为数据。")])]),a._v(" "),r("li",[r("p",[a._v("实时数据处理：kafka 适合于实时数据处理场景，它可以实时地消费数据并进行数据分析。")])]),a._v(" "),r("li",[r("p",[a._v("事件驱动架构：kafka 适合于事件驱动架构，它可以用于解耦生产者和消费者，实现事件的发布和订阅。")])]),a._v(" "),r("li",[r("p",[a._v("流式处理：kafka 适合于流式处理场景，它可以实时地消费数据并进行数据分析。")])]),a._v(" "),r("li",[r("p",[a._v("机器学习：kafka 适合于机器学习场景，它可以实时地消费数据并进行数据分析。")])]),a._v(" "),r("li",[r("p",[a._v("消息系统：kafka 适合于消息系统，它可以用于解耦生产者和消费者，实现消息的发布和订阅。")])]),a._v(" "),r("li",[r("p",[a._v("日志聚合：kafka 适合于日志聚合场景，它可以收集和处理大量的日志数据。")])]),a._v(" "),r("li",[r("p",[a._v("应用监控：kafka 适合于应用监控场景，它可以实时地消费应用的性能数据。")])]),a._v(" "),r("li",[r("p",[a._v("广告点击日志：kafka 适合于广告点击日志场景，它可以收集和处理大量的日志数据。")])]),a._v(" "),r("li",[r("p",[a._v("股票交易数据：kafka 适合于股票交易数据场景，它可以实时地消费股票交易数据。")])]),a._v(" "),r("li",[r("p",[a._v("物联网数据：kafka 适合于物联网数据场景，它可以实时地消费物联网数据。")])]),a._v(" "),r("li",[r("p",[a._v("订单处理数据：kafka 适合于订单处理数据场景，它可以实时地消费订单处理数据。")])]),a._v(" "),r("li",[r("p",[a._v("运维监控：kafka 适合于运维监控场景，它可以实时地消费运维数据")])])]),a._v(" "),r("p",[a._v("kafka 常用代码")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v('java\n// 生产者\nProperties props = new Properties();\nprops.put("bootstrap.servers", "localhost:9092");\nprops.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");\nprops.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");\n\nKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\nproducer.send(new ProducerRecord<>("my-topic", "key", "value"));\n\n// 消费者\nProperties props = new Properties();\nprops.put("bootstrap.servers", "localhost:9092");\nprops.put("group.id", "my-group");\nprops.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");\nprops.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");\n\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Collections.singletonList("my-topic"));\n\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records)\n        System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());\n}\n')])])])])}),[],!1,null,null,null);r.default=i.exports}}]);